---
title: "uber"
author: "Valeriy Kondruk"
date: "11 07 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# UBER perks problem


UBER has introduced the new perks for its drivers recently. One of the perks is the full tuition for the ASU online. Driver needs to make 3000 trips to be able t claim this particular perk. I have a data of a driver who has been driving for 43 weeks. At the time the driver had completed 2091 trips. My goal is to calculate the number of weeks this driver would need to drive to get his ASU Online tuition covered by UBER. 

## Outline the research process

We have a data set covering 43 consequtive weeks of driving history - a sample with 43 observations. Using this sample, we want to make an inference about the population (all possible weeks for this particular driver). 

1. Import and clean data
2. Calculate the descriptive statistics, build the distribution plot
3. Calculate confidence interval
4. Find min and max number of weeks to reach the perk  

5. More research questions

### Import and clean data

```{r echo=FALSE, warning=FALSE, results='hide', message=FALSE, error=FALSE}
# plyr is handy for multiple csv import 
library(plyr)

library(dplyr)
library(ggplot2)
library(readxl)
library(readr)

# package lubridate for easy date/time handling. check if the package is installed already. install it if it's not.
if (!require(lubridate)) install.packages("lubridate", repos="http://cran.us.r-project.org")

library(lubridate)
```

We have already imported the data from Excel file and saved as uber_stats.Rdata file.

```{r uber}
# uber_stats <- read_delim("uber_stats.csv", 
#     ";", escape_double = FALSE, na = "NA", 
#     trim_ws = TRUE)
# View(uber_stats)
# save(uber_stats, file = "uber_stats.Rdata")
load("uber_stats.Rdata")
```

We have the weekly data spanning between September 17, 2018 and July 15, 2019. Data for some of the weeks is unavailable as driver didn't drive those weeks. For this research, we will eliminate the empty weeks.

### Calculate the descriptive statistics, build the distribution plot

```{r warning=FALSE, message=FALSE, error=FALSE}
trips_stat <- uber_stats %>%
  summarise(trips_mean = mean(as.numeric(uber_stats$`Number of trips`), na.rm = TRUE), trips_sd = sd(as.numeric(uber_stats$`Number of trips`), na.rm = TRUE), trips_min = min(as.numeric(uber_stats$`Number of trips`), na.rm = TRUE), trips_max = max(as.numeric(uber_stats$`Number of trips`), na.rm = TRUE))

paid_weeks <- uber_stats %>%
  filter(!is.na(as.numeric(uber_stats$`Number of trips`)), n())

nonzero_weeks_count <- NROW(paid_weeks$`Number of trips`)

# It's hard to pick the right number of bins for the following histogram, so we're using Sturge's Rule (K = 1 + 3. 322 logN). Where K is nthe number of bins and N is the number of observations.

show(1 + 3.322*log(nonzero_weeks_count))

# We need approximately 13 bins for the plot. We ended up with 8, though.

paid_weeks %>%
  ggplot(aes(as.numeric(paid_weeks$`Number of trips`))) +
  geom_histogram(binwidth = 10, fill = "orange", colour = "black")

```

We have a nearly normal distribution with a left skew. The mean is 52.5 and standard deviation is 18.3. We doubt if we should use the Poisson distribution instead as we're dealing with the number of event happening in equal and consequtive periods of time. We keep it normal for now.

### Calculate confidence interval
  
We are calculating the confidence interval as (point of estimate +- z*SE).

```{r}
SE_trips <- trips_stat$trips_sd / sqrt(nonzero_weeks_count)
z_trips <- abs(qnorm(0.025))
margin_of_error_trips <- z_trips*SE_trips
ci_trips <- trips_stat %>%
  summarise(lower = trips_mean - margin_of_error_trips, upper = trips_mean + margin_of_error_trips)
```

We found our confidence interval at 95% confidence level to be from `r round(ci_trips$lower, 1)` to `r round(ci_trips$upper, 1)` trips per week.
  
### Find min and max number of weeks to reach the perk

```{r}
remaining_weeks_min <- round((3000 - 2091) / ci_trips$upper, 1)
remaining_weeks_max <- round((3000 - 2091) / ci_trips$lower, 1)

```

Considering that the rider already made 2091 trips, it will take this driver at least `r remaining_weeks_min` weeks and at most `r remaining_weeks_max` weeks to reach 3000 trips.


# More research questions
  
## On which day of the week riders tip most frequently?
  
That would be great to know if there's any correlation between the day of the week and tip amount and frequency a driver gets. For this analysis, we need to get a data set with separate trips (not just weekly data we used before).  

  
### Getting data from multiple csvs
  
We have a raw data in Uber weekly statements that we want to put into one data set. 

```{r warning=FALSE, message=FALSE, error=FALSE}

# We first put all csvs into dedicated folder. Then, we create a list of all files in csv folder.

mydir = "csv"
myfiles = list.files(path=mydir, pattern="*.csv", full.names=TRUE)

# We use ldply function from plyr library to build a data frame from multiple csv files using read_csv function from readr library.

uber_trips = ldply(myfiles, read_csv)

names(uber_trips)
```

Fortunately, raw data already show a day of the week for each trip, so we don't need to take extra steps to transform date into days of the week. However, we would need to split the 'Date/Time' parameter into 'Date/Time' and 'Weekday'.
  
```{r date_time_separation}
# create new column, convert Date/Time data in a proper format then extract the week day

uber_trips <- uber_trips %>%
  mutate(date_time = as.POSIXct(strptime(uber_trips$`Date/Time`, format = "%A, %B %d, %Y %I:%M %p"))) %>%
  # assign week day: time after midnight (till 5 am) considered a previous day since the shift isn't over 
  mutate(week_day = ifelse(hour(date_time) > 5, weekdays(date_time, abbreviate = TRUE), (weekdays(as.Date(date_time)-1, abbreviate = TRUE))))
```

*Please, note that driver's shift often spans from evening to late night. Thus, for this particular analysis we don't switch the day right after midnight and we keep the same day until 5am in the morning. This way a tip recieved on a Sunday's late night ride considered a Sunday's tip, not Monday's which makes sense.*   

All currency columns need to be converted into numerical format.

```{r change_formats}
# create a function which converts char variable into currency variable
currency <- function(x, na.rm = TRUE) (as.numeric(sub('$','',as.character(x),fixed=TRUE)))

# create a list of all columns to be converted
char_list <- colnames(select_if(uber_trips, is.character))
                      
# exclude all non-currency columns
char_list = char_list[- c(1, 2, 3, 4, 5, 20)]
char_list[15] = "Promotions"
char_list[16] = "Cleaning Repairs"
  
# change the format for currency columns. We use new data frame to avoid any data loss
uber_trips_clean <- uber_trips %>%
  mutate_at(char_list, currency, na.rm = TRUE)

# order data frame by date_time (ascending order)
uber_trips_clean <- arrange(uber_trips_clean, date_time)
```

  
### Summary statistics
  
Chack summary statistics and parameter distributions.

```{r summary_statistics}
# Summary stats for Tip variable
uber_trips_clean %>% 
  filter(!is.na(Tip)) %>%
  summarise(tip_mean = mean(as.numeric(Tip,  na.rm = TRUE)), tip_min = min(as.numeric(Tip)), tip_max = max(as.numeric(Tip,  na.rm = TRUE)), tip_sd = sd(as.numeric(Tip))) %>%
  show()

uber_trips_clean %>%
  filter(!is.na(Tip)) %>%
  ggplot(aes(x = Tip)) +
  geom_histogram(binwidth = 3, fill="orange", colour="black") 
```

'Tip' variable represent a right-skewed unimodal distribution with several extreme outliers (more than 3 standard deviations from the mean).
  
### Find dyas when tips received most frequently

```{r}
# Build a frequency plot
uber_trips_clean %>%
  filter(!is.na(Tip)) %>%
  ggplot(aes(y = Tip, x = week_day)) +
  geom_bin2d() +
  scale_fill_gradient(low = "yellow", high="red")

# Number of trips with tip and trips per week day
days_stat <- uber_trips_clean %>%
  group_by(week_day) %>%
  summarise(trips_w_tip = sum(!is.na(Tip)), trips_total = n(), tip_frequency = trips_w_tip/trips_total)

days_stat

# Tip frequency histogram
days_stat %>%
  ggplot(aes(x = tip_frequency)) +
  geom_histogram(binwidth = 0.015, fill="orange", colour="black")

```
  
## ANOVA hypothesis test
  
From the statistics above, we can see that Fridays and Thursdays are the days when riders tip most often. However, tip frequency for all week days is quite close. 

It's interesting to check whether the differencies in frequencies are due to chance or not. We'll be using ANOVA test to find out.
  
### Set up hypothesis
  
H0: Average tip frequency is the same around the week  
HA: Average tip frequency differs at least on one day

Significance level (&alpha;) = 0.05
  
### Prepare data
  
All of the observations in our data represent separate rides. To be able to analyze certain days as observations, we need to make some tweaks:

```{r create_shift_day}
# we create a new variable shift_date which differs from the actual date if the trip done after midnight but before 5am (explained earlier)
uber_trips_clean <- uber_trips_clean %>%
  mutate(shift_date = ifelse(hour(date_time) > 5, as.character(date(date_time)), as.character(date(date_time) - 1)))

# combine week day name and shift date to create  
uber_trips_clean$shift <- paste(uber_trips_clean$week_day, uber_trips_clean$shift_date)

# create a separate data frame with shifts observations
uber_shifts <- uber_trips_clean %>%
  group_by(shift) %>%
  summarise(weekday = first(week_day), trips_w_tip = sum(!is.na(Tip)), trips_total = n(), tip_frequency = trips_w_tip/trips_total)

```

### Check summary statistics

We need to check the form of tip frequency distribution, mean, and variability. 

```{r}
# summary statistics table
uber_shifts %>%
  summarise(days_total = n(), frequency_mean = mean(tip_frequency), frequency_sd = sd(tip_frequency))

# build a histogram for tip frequency
uber_shifts %>%
  ggplot(aes(x = tip_frequency)) +
  geom_histogram(binwidth = 0.075, fill="orange", colour="black")

```

The histogram above shows a nearly normal distribution with a slight right skew. There are extreme outliers (over 3 sd's from the mean).

Summary statistics grouped by week days:  

```{r}
# calculate variability within the groups
uber_shifts_summary <- uber_shifts %>%
  group_by(weekday) %>%
  summarise(wday_size = n(), wday_mean = mean(tip_frequency), wday_sd = sd(tip_frequency))

uber_shifts_summary
```

Thursday seems to be the day with the highest proportion of trips with tip to the total number of trips (`r round(uber_shifts_summary$wday_mean[5], 3)`). Friday follows closely (`r round(uber_shifts_summary$wday_mean[1], 3)`). Sunday has the lowest tip to trips ratio of `r round(uber_shifts_summary$wday_mean[4], 3)`.

  
### Check conditions - ANOVA graphical diagnostics
  
#### Independence  
  
Considering the fact that we analyze data for one driver only, it's unclear if daily observations are independent of each other. In case of consequitive days (Thursday, Friday, Saturday, etc.), there's a good chance that they are not independent in terms of driver's behavior, car condition and other factors that influence tipping. However, for example, two Fridays of different weeks (even if consequitive) and months are most likely to be independent. There are not obvious reasons why independence would not hold for most or all observations.

  
#### Normality  
  
The normality assumption is especially important when the sample size is quite small. The normal probability plots for each week day are shown below:

```{r ANOVA_graphical_diagnostics}

# build the normal probability plots for all seven groups
for (i in c("Sun", "Mon", "Tue", "Wed", "Thu", "Fri", "Sat")) {
uber_shifts_days <- uber_shifts %>%
  filter(weekday == i)
qqnorm(uber_shifts_days$tip_frequency, main = i, col="orange")
qqline(uber_shifts_days$tip_frequency)
}

```

* Sun - points follow an S-shaped curve which indicates short tails (narrower than the normal distribution)
* Mon - not clear
* Tue - ponts start below the line, bend to follow it, and end above it which indicates long tails (wider than the normal distribution)
* Wed - points bend up and to the left of the line - obviously, right skew
* Thu - right skew
* Fri - nearly normal
* Sat - nearly normal  

There are some deviation from normality for most of the week days except Friday and Saturday. The sample sizes are not large. The outliers are not extreme, though. The normality of the distributions can be a concern in this case. 
  
#### Constant variance    
  
The last assumption is that the variance in the groups is about equal from one group to the next. This assumption can be checked by examining a side-by-side box plot of the tipping frequency across the week days.

```{r}
boxplot(uber_shifts$tip_frequency ~ uber_shifts$weekday, col="orange",  main = "Tip frequency distribution by week day", ylab = "Proportion of trips with tips", xlab = "Week day")
```

In this case, the variability is **similar in the 7 groups but not identical**. We saw in a previous section that the standard deviation varies a bit from one group to the next. Whether these differences are from natural variation is unclear.


### Compute one-way ANOVA test

Now, we want to calculate the test results. We can use the F statistic to evaluate the hypotheses in what is called an F test. 

Analysis of variance (ANOVA) is used to test whether the mean outcome differs across 2 or more groups. The test statistic F represents a standardized ratio of variability in the sample means relative to the variability within the groups. If H0 is true and the model assumptions are satisfied, the statistic F follows an F distribution with parameters df1 = k - 1 and df2 = n - k. The upper tail of the F distribution is used to represent the p-value.

```{r}
# Compute the analysis of variance
results_aov <- aov(tip_frequency ~ weekday, data = uber_shifts)

# Summary of the analysis
summary(results_aov)
```

The calculated p-value is 0.365, which is larger than 0.05, indicating the evidence is not strong enough to reject the null hypothesis at a significance level of 0.05. That is, **the data do not provide strong evidence that the average tip frequency varies by week day.** The variance we saw could be due to chance.
  
  

### Check ANOVA assumptions with other methods

*The following tests has been adopted from the article on STHDA (http://www.sthda.com/english/wiki/one-way-anova-test-in-r). 

The ANOVA test assumes that, the data are normally distributed and the variance across groups are homogeneous. We can check that with some diagnostic plots.

#### Homogenity of variance

The residuals versus fits plot can be used to check the **homogeneity of variances**.

```{r}
# Homogeneity of variances
plot(results_aov, 1)
```

*I'm not sure how to interpret this plot and need to get back to it once I learn more* However, it looks pretty similar to one in the article. It could mean that there is no evident relationships between residuals and fitted values (the mean of each groups), which is good. So, we can assume the homogeneity of variances.

It’s also possible to use **Levene’s test** to check the homogeneity of variances.

```{r}
if (!require(car)) install.packages("car", repos="https://cran.r-project.org/")
library(car)
leveneTest(tip_frequency ~ weekday, data = uber_shifts)
```

From the output above we can see that the p-value is not less than the significance level of 0.05. This means that there is no evidence to suggest that the variance across groups is statistically significantly different. Therefore, we can assume the homogeneity of variances in the different treatment groups.

The Levene's test is not significant. The homogeneity is fine.

#### Normality

Normality plot of residuals. In the plot below, the quantiles of the residuals are plotted against the quantiles of the normal distribution. A 45-degree reference line is also plotted.

The normal probability plot of residuals is used to check the assumption that the residuals are normally distributed. It should approximately follow a straight line.

```{r}
# Normality
plot(results_aov, 2)
```

In fact, we see the signs of a right skew here (points bend up and to the left of the line). As the distribution is not perfectly normal, it would be handy to run a **Shapiro-Wilk test** on the ANOVA residuals. 

```{r}
# Extract the residuals
aov_residuals <- residuals(object = results_aov )
# Run Shapiro-Wilk test
shapiro.test(x = aov_residuals )
```

The p-value is lower than 0.05 significance level, which means that there's less than 1% chance of seeing this distribution if it was in fact normal. Thus, *the normality assumption is not satisfied.*


### Non-parametric alternative to one-way ANOVA test

There are concerns about normality in our analysis. We can try using a non-parametric alternative to a one-way ANOVA -  **Kruskal-Wallis** rank sum test, which can be used when ANOVA assumptions are not met.

```{r}
kruskal.test(tip_frequency ~ weekday, data = uber_shifts)
```

Employing a Kruskal-Wallis test, we've got a p-value of 0.4322, which is significantly larger than 0.05, meaning that there's not enough evidence to reject the null hypothesis.


### Conclusion for the tip frequency analysis

We run ANOVA and Kruskal-Wallis tests to check the hypothesis that UBER riders tip more often on certain days of the week. Neither test could provide significant evidence to reject the null hypothesis at 5% significance level. 

We then conclude that there's in fact no difference between the week days if we talk about how often riders tip this particular driver. Otherwise, we could make a Type II error and failed to reject the null hypothesis when in fact riders tip more often on certain week days.

There are concerns that should be mentioned. First, the normality of the distribution. Second, the sample size for some of the groups (for example, we only have data for 12 Mondays). 